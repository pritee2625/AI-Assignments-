{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Question 2: CIFAR-10 dataset reconstruction\n",
        "Dataset Problem: Use the CIFAR-10 dataset to train an autoencoder. The goal is to input an image of a CIFAR-10 dataset into the autoencoder and have it reconstructed the image as a new output. Use the concept of VAE to solve this problem\n",
        "CIFAR is an acronym that stands for the Canadian Institute for Advanced Research and the\n",
        "CIFAR-10 dataset was developed along with the CIFAR-100 dataset by researchers at the CIFAR institute. The dataset is comprised of 60,000 32 X 32-pixel color photographs of objects from10 classes, such as frogs, birds, cats, ships, etc. The class labels and their standard associated\n",
        "integer values are listed below.\n",
        "\n",
        "0: airplane\n",
        "1: automobile\n",
        "2: bird\n",
        "3: cat\n",
        "4: deer\n",
        "5: dog\n",
        "6: frog\n",
        "7: horse\n",
        "8: ship\n",
        "9: truck\n"
      ],
      "metadata": {
        "id": "lPlGxoHjrAM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Function to unpickle CIFAR-10 batch files\n",
        "def unpickle(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict_data = pickle.load(fo, encoding='bytes')\n",
        "    return dict_data\n",
        "\n",
        "# List of uploaded files\n",
        "file_paths = [\n",
        "    \"/content/batches.meta\",\n",
        "    \"/content/data_batch_1\",\n",
        "    \"/content/data_batch_2\",\n",
        "    \"/content/data_batch_3\",\n",
        "    \"/content/data_batch_4\",\n",
        "    \"/content/data_batch_5\",\n",
        "    \"/content/test_batch\"\n",
        "]\n",
        "\n",
        "# Load and display the first batch as an example\n",
        "data_batch_1 = unpickle(file_paths[1])\n",
        "\n",
        "# Print keys in the dictionary to explore the data structure\n",
        "print(data_batch_1.keys())\n",
        "\n",
        "# Extract images and labels\n",
        "images = data_batch_1[b'data']\n",
        "labels = data_batch_1[b'labels']\n",
        "\n",
        "# Display shape of the data\n",
        "print(f\"Shape of images array: {images.shape}\")\n",
        "print(f\"Number of labels: {len(labels)}\")"
      ],
      "metadata": {
        "id": "B6yf6OSV3hKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc25bf79-5f90-4e6e-c123-d9d5d7671792"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n",
            "Shape of images array: (10000, 3072)\n",
            "Number of labels: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Data Preparation:"
      ],
      "metadata": {
        "id": "Fo1Hs0Qyw_PH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, _), (x_test, _) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n"
      ],
      "metadata": {
        "id": "ORptAnaWf3IS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "705b8641-fab1-4509-dde6-eae37cabe9dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Define the VAE Architecture:"
      ],
      "metadata": {
        "id": "F9FD28wHxNOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "latent_dim = 128  # Dimension of the latent space\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = tf.keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(32, 3, activation='relu', strides=2, padding='same')(encoder_inputs)\n",
        "x = layers.Conv2D(64, 3, activation='relu', strides=2, padding='same')(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "z_mean = layers.Dense(latent_dim, name='z_mean')(x)\n",
        "z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)\n",
        "\n",
        "# Sampling function\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    batch = tf.shape(z_mean)[0]\n",
        "    dim = tf.shape(z_mean)[1]\n",
        "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "z = layers.Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = tf.keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(8 * 8 * 64, activation='relu')(decoder_inputs)\n",
        "x = layers.Reshape((8, 8, 64))(x)\n",
        "x = layers.Conv2DTranspose(64, 3, activation='relu', strides=2, padding='same')(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation='relu', strides=2, padding='same')(x)\n",
        "decoder_outputs = layers.Conv2DTranspose(3, 3, activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Define encoder and decoder models\n",
        "encoder = tf.keras.Model(encoder_inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "decoder = tf.keras.Model(decoder_inputs, decoder_outputs, name='decoder')"
      ],
      "metadata": {
        "id": "qCoMM7b0f3FS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Define the VAE Model with Custom Loss:"
      ],
      "metadata": {
        "id": "MrM0s2eYxRIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(tf.keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var, z = self.encoder(inputs)\n",
        "        reconstructed = self.decoder(z)\n",
        "        return reconstructed\n",
        "\n",
        "# Instantiate the VAE model\n",
        "vae = VAE(encoder, decoder)\n"
      ],
      "metadata": {
        "id": "DZs04R1ef2_-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Compile and Train the Model:"
      ],
      "metadata": {
        "id": "JPH-7TJwxTzd"
      }
    },
    {
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var, z = self.encoder(inputs)\n",
        "        reconstructed = self.decoder(z)\n",
        "        return reconstructed\n",
        "\n",
        "    def compute_loss(self, x, *args, **kwargs): # Modified line\n",
        "        z_mean, z_log_var, z = self.encoder(x)\n",
        "        x_reconstructed = self.decoder(z)\n",
        "\n",
        "        # Reconstruction loss\n",
        "        reconstruction_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(x, x_reconstructed))\n",
        "\n",
        "        # KL divergence loss\n",
        "        kl_loss = -0.5 * tf.reduce_mean(z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
        "\n",
        "        return reconstruction_loss + kl_loss\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = self.compute_loss(data) # data contains x, y, sample_weight\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        return {\"loss\": loss}\n",
        "\n",
        "# Initialize model\n",
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
        "\n",
        "# Train the model\n",
        "vae.fit(x_train, epochs=4, batch_size=127, validation_data=(x_test, None))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "dEAZ5cLMukJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Evaluate and Visualize the Results"
      ],
      "metadata": {
        "id": "guOGr5ApxZ4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Select a few test images\n",
        "num_images = 10\n",
        "sample_images = x_test[:num_images]\n",
        "reconstructed_images = vae.predict(sample_images)\n",
        "\n",
        "# Plot original and reconstructed images\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(num_images):\n",
        "    # Original images\n",
        "    ax = plt.subplot(2, num_images, i + 1)\n",
        "    plt.imshow(sample_images[i])\n",
        "    plt.title(\"Original\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Reconstructed images\n",
        "    ax = plt.subplot(2, num_images, i + 1 + num_images)\n",
        "    plt.imshow(reconstructed_images[i])\n",
        "    plt.title(\"Reconstructed\")\n",
        "    plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JlAfwYIOf26t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6.Code to Evaluate VAE Performance Using SSIM and MSE"
      ],
      "metadata": {
        "id": "H6Q_lD8vxd-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to compute SSIM and MSE\n",
        "def evaluate_reconstruction(vae, x_test):\n",
        "    num_samples = 100  # Number of test images to evaluate\n",
        "    x_test_sample = x_test[:num_samples]\n",
        "\n",
        "    # Generate reconstructed images\n",
        "    reconstructed_images = vae.predict(x_test_sample)\n",
        "\n",
        "    ssim_scores = []\n",
        "    mse_scores = []\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        # Compute SSIM (Structural Similarity Index)\n",
        "        ssim_score = ssim(x_test_sample[i], reconstructed_images[i], multichannel=True)\n",
        "        ssim_scores.append(ssim_score)\n",
        "\n",
        "        # Compute MSE (Mean Squared Error)\n",
        "        mse_score = np.mean((x_test_sample[i] - reconstructed_images[i]) ** 2)\n",
        "        mse_scores.append(mse_score)\n",
        "\n",
        "    avg_ssim = np.mean(ssim_scores)\n",
        "    avg_mse = np.mean(mse_scores)\n",
        "\n",
        "    print(f\"Average SSIM Score: {avg_ssim:.4f}\")  # Higher is better (1 is perfect reconstruction)\n",
        "    print(f\"Average MSE Score: {avg_mse:.4f}\")  # Lower is better (0 means identical images)\n",
        "\n",
        "# Call the evaluation function\n",
        "evaluate_reconstruction(vae, x_test)"
      ],
      "metadata": {
        "id": "6lyvChZRf23m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s6GgiXmMqYuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8JVcB1QHqYw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OLAE4CxGqY2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cMYmKdCFqZA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0JPvZsMuqZEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eiFvuwKEqZL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ghslw1ETqZOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FXPcVqjuqZRG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}