{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Question 1: Sentiment Analysis with Transformers\n",
        "Dataset Problem: Use the IMDB movie reviews dataset to perform sentiment analysis using a Transformer model. load the dataset from TensorFlow datasets library and solve the problem.\n",
        "Due to the complexity and size of Transformer models, use via libraries like Hugging Face's Transformers and work it out, feel free to experiment with more than 1 transformer model and compare the results and give a short explanation on the best model, what are the reasons for its performance.  \n"
      ],
      "metadata": {
        "id": "8jkn9aEONZq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import sklearn\n",
        "from tqdm import tqdm\n",
        "df=pd.read_csv(\"/content/IMDB Dataset.csv\")\n",
        "df.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cmi7FMzlKieO",
        "outputId": "7b1f99d8-5428-41b0-8241-86b39d9e857c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review sentiment\n",
              "28382  This one grew on me. I love the R.D. Burman mu...  positive\n",
              "8318   If this could be rated a 0, it would be. From ...  negative\n",
              "17764  \"A Mouse in the House\" is a very classic carto...  positive\n",
              "14961  I'm watching this film as I write this. It's a...  negative\n",
              "47897  I have officially vomited in my own mouth, tha...  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e978fc4-bb8d-4263-b396-d0a4d879e9ad\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28382</th>\n",
              "      <td>This one grew on me. I love the R.D. Burman mu...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8318</th>\n",
              "      <td>If this could be rated a 0, it would be. From ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17764</th>\n",
              "      <td>\"A Mouse in the House\" is a very classic carto...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14961</th>\n",
              "      <td>I'm watching this film as I write this. It's a...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47897</th>\n",
              "      <td>I have officially vomited in my own mouth, tha...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e978fc4-bb8d-4263-b396-d0a4d879e9ad')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3e978fc4-bb8d-4263-b396-d0a4d879e9ad button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3e978fc4-bb8d-4263-b396-d0a4d879e9ad');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4bdec06a-b49b-429b-a0f7-4889a613db4e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4bdec06a-b49b-429b-a0f7-4889a613db4e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4bdec06a-b49b-429b-a0f7-4889a613db4e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"If this could be rated a 0, it would be. From the atrocious wooden acting to the dull, plodding pace, the puerile exploitation angle and the sophomoric pseudolesbian titillation added purely for the sake of the sad viewers, this is a disaster of a film.<br /><br />The plot is predictable, as from the beginning one is absolutely certain of what will happen to all of the characters and how the plot will commence. From a boring, unexceptional beginning to a pathetic and bleak ending, every single presence in this film is wasted, and every meagre scrap of talent dug up for this turkey is squandered.<br /><br />If you want to watch something as relentlessly bleak with plenty of the same childish titillation, watch one of the Ilsa films. At least they're unapologetic and up-front about what they're trying to do. How something this horrendously bad ever managed to be rated above a 5 is a miracle of how people with no taste or discerning standards can sometimes come together for the most dubious of purposes.<br /><br />It's not scary, it's not interesting, and above all it's not arousing in any sense of the word. It is, in my opinion, a crime; it is a crime that such a horribly offensive and incompetent piece of trash was ever conceived of and given the resources to come into existence, and even more a tragedy that it is still defended by some woefully misguided viewers.<br /><br />Not even Elvira's cheerful personality and joking ways could soften the blow that this horrifying travesty of film is. Avoid it at all costs.\",\n          \"I have officially vomited in my own mouth, thanks to this movie.<br /><br />I expected the absolute worst with this movie, but I expected a heartwarming and pleasurable absolute worst. This is just terrible. Absolutely terrible. Terrible like Nazis spreading the black plague. Let me explain: Ewoks are speaking English. It's horrible.<br /><br />The villain girl looks like she travelled from the future set of Power Rangers. I really really want her to rise up from the ground and say \\\"At last! After ten thousand years I'm free! It's time to conquer Earth!\\\" The putties... er, I mean the big bad whatever the heck they are... they growl a lot. Many of them look like an even lamer version of the Cryptkeeper. The Cryptkeeper was pretty cool, but these guys were not.<br /><br />The only merit to this movie was Paul Gleason. This movie might have been better if he'd went to the bad guys and said \\\"If I have to come in here again, I'm crackin' skulls.\\\" It would have been even better if one of the Ewoks was played by Judd Nelson, who mouthed his words as he said this.<br /><br />Also, that speedy little creature is pretty badass. Word to that.<br /><br />No word to the movie, though. I want to give this movie a two. I want to, so badly. There's a passage I have memorized: The path of this movie is beset on all sides by the inequities of terribleness and the tyranny of spin-off awfulness. Blessed is nothing, for this movie blows.\",\n          \"\\\"A Mouse in the House\\\" is a very classic cartoon by Tom & Jerry, faithful to their tradition but with jokes of its own. It is hysterical, hilarious, very entertaining and quite amusing. Artwork is of good quality either.<br /><br />This short isn't just about Tom trying to catch Jerry. Butch lives in the same house and he's trying to catch the mouse too, because \\u00abthere's only going to be one cat in this house in the morning -- and that's the cat that catches the mouse\\u00bb.<br /><br />If you ask me, there are lots of funny gags in this cartoon. The funniest for me are, for example, when Mammy Two Shoes sees the two lazy cats sleeping and says sarcastically \\u00abI'm glad you're enjoying the siesta\\u00bb and that she hopes they're satisfied because she ain't, making the two cats gasp. Another funny gag is when Tom disguises himself as Mammy Two Shoes and slams Butch with a frying pan and then Butch does the same trick to Tom. Of course that, even funnier than this, is when the real Mammy Two Shoes appears and both (dumb!) cats think they are seeing each other disguised as Mammy and then they both attack her on the \\\"rear\\\" - lol. Naturally that she gets mad and once she gets mad, she isn't someone to mess with. But even Jerry doesn't win this time, because he is expelled by her too.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #Installing Transformers library\n",
        " !pip install transformers"
      ],
      "metadata": {
        "id": "Tz6cZIQjLGN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the BERT Classifier and Tokenizer along with Input module\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from transformers import InputExample, InputFeatures\n",
        "\n",
        "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "EBTHxrAvLGLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# changing positive and negative into numeric values\n",
        "\n",
        "def cat2num(value):\n",
        "    if value=='positive':\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "df['sentiment']  =  df['sentiment'].apply(cat2num)\n",
        "train = df[:45000]\n",
        "test = df[45000:]"
      ],
      "metadata": {
        "id": "31lUVIc_LGJZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing\n",
        "For training model with BERT, we need to do some additional Prepriocessing. Let's understand them one by one!\n",
        "\n",
        "Add special tokens to separate sentences and do classification\n",
        "Pass sequences of constant length (introduce padding)\n",
        "Create array of 0s (pad token) and 1s (real token) called attention mask"
      ],
      "metadata": {
        "id": "BmCKVzoMLVa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #But first see BERT tokenizer exmaples and other required stuff!\n",
        "\n",
        "example='In this Kaggle notebook, I will do sentiment analysis using BERT with Huggingface'\n",
        "tokens=tokenizer.tokenize(example)\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(tokens)\n",
        "print(token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FET8nQY6LGG5",
        "outputId": "f1fb22e7-623b-4241-ff65-75ac8222bef5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['in', 'this', 'ka', '##ggle', 'notebook', ',', 'i', 'will', 'do', 'sentiment', 'analysis', 'using', 'bert', 'with', 'hugging', '##face']\n",
            "[1999, 2023, 10556, 24679, 14960, 1010, 1045, 2097, 2079, 15792, 4106, 2478, 14324, 2007, 17662, 12172]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_data_to_examples(train, test, review, sentiment):\n",
        "    train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
        "                                                          text_a = x[review],\n",
        "                                                          label = x[sentiment]), axis = 1)\n",
        "\n",
        "    validation_InputExamples = test.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
        "                                                          text_a = x[review],\n",
        "                                                          label = x[sentiment]), axis = 1,)\n",
        "\n",
        "    return train_InputExamples, validation_InputExamples\n",
        "\n",
        "train_InputExamples, validation_InputExamples = convert_data_to_examples(train,  test, 'review',  'sentiment')"
      ],
      "metadata": {
        "id": "1ymoeGDELGEj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\n",
        "    features = [] # -> will hold InputFeatures to be converted later\n",
        "\n",
        "    for e in tqdm(examples):\n",
        "        input_dict = tokenizer.encode_plus(\n",
        "            e.text_a,\n",
        "            add_special_tokens=True,    # Add 'CLS' and 'SEP'\n",
        "            max_length=max_length,    # truncates if len(s) > max_length\n",
        "            return_token_type_ids=True,\n",
        "            return_attention_mask=True,\n",
        "            pad_to_max_length=True, # pads to the right by default # CHECK THIS for pad_to_max_length\n",
        "            truncation=True\n",
        "        )\n",
        "\n",
        "        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n",
        "        features.append(InputFeatures( input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label) )\n",
        "\n",
        "    def gen():\n",
        "        for f in features:\n",
        "            yield (\n",
        "                {\n",
        "                    \"input_ids\": f.input_ids,\n",
        "                    \"attention_mask\": f.attention_mask,\n",
        "                    \"token_type_ids\": f.token_type_ids,\n",
        "                },\n",
        "                f.label,\n",
        "            )\n",
        "\n",
        "    return tf.data.Dataset.from_generator(\n",
        "        gen,\n",
        "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
        "        (\n",
        "            {\n",
        "                \"input_ids\": tf.TensorShape([None]),\n",
        "                \"attention_mask\": tf.TensorShape([None]),\n",
        "                \"token_type_ids\": tf.TensorShape([None]),\n",
        "            },\n",
        "            tf.TensorShape([]),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "\n",
        "DATA_COLUMN = 'review'\n",
        "LABEL_COLUMN = 'sentiment'"
      ],
      "metadata": {
        "id": "tPX3I577LGCR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n",
        "train_data = train_data.shuffle(100).batch(32).repeat(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJtkAJAFLF_g",
        "outputId": "d9d1019b-8a54-4514-8774-0bff8d2fd4c6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/45000 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2700: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "100%|██████████| 45000/45000 [03:52<00:00, 193.83it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\n",
        "validation_data = validation_data.batch(32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlV4U3BTLnIZ",
        "outputId": "26df3b3e-ec14-4741-cdb7-f9599eb79186"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:25<00:00, 196.32it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
        "\n",
        "model.fit(train_data, epochs=2, validation_data=validation_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkf9iBT2QDk6",
        "outputId": "6d813c9c-ab54-46a6-dc64-925983909950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "      4/Unknown - 244s 48s/step - loss: 0.6860 - accuracy: 0.5781"
          ]
        }
      ]
    },
    {
      "source": [
        "# Loading the BERT Classifier and Tokenizer along with Input module\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from transformers import InputExample, InputFeatures\n",
        "\n",
        "# The following line was missing in your original code:\n",
        "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "tbjyFR_oN8Zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_sentences = ['worst movie of my life, will never watch movies from this series', 'Wow, blew my mind, what a movie by Marvel, animation and story is amazing']"
      ],
      "metadata": {
        "id": "arEDTpbcLnCz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "source": [
        "import tensorflow as tf # This line was missing\n",
        "\n",
        "tf_batch = tokenizer(pred_sentences, max_length=128, padding=True, truncation=True, return_tensors='tf')   # we are tokenizing before sending into our trained model\n",
        "tf_outputs = model(tf_batch)\n",
        "tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)       # axis=-1, this means that the index that will be returned by argmax will be taken from the *last* axis.\n",
        "labels = ['Negative','Positive']\n",
        "label = tf.argmax(tf_predictions, axis=1)\n",
        "label = label.numpy()\n",
        "for i in range(len(pred_sentences)):\n",
        "    print(pred_sentences[i], \": \", labels[label[i]])"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkIyUsx1OXtL",
        "outputId": "5e654ace-c49f-47d3-95ee-b05ea7f77ccf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "worst movie of my life, will never watch movies from this series :  Positive\n",
            "Wow, blew my mind, what a movie by Marvel, animation and story is amazing :  Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 2: Text Generation with Transformers\n",
        "Dataset Problem: Using a pre-trained GPT model (any version) from Hugging Face's Transformers, generate a short story based on a given prompt. Example prompt is below\n",
        "Prompt=” In a distant future, humanity has discovered”\n"
      ],
      "metadata": {
        "id": "srLQ50SyNiFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch numpy"
      ],
      "metadata": {
        "id": "btOaQ4f6Lm4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "\n",
        "model_name = \"gpt2\"  # You can choose a different model on hugging face or fine-tune a model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "spcAGPmSO5ML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"In a distant future, humanity has discovered\"\n",
        "\n",
        "# Tokenize input\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
        "\n",
        "# Create an attention mask\n",
        "attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n",
        "\n",
        "# Generate text with attention mask\n",
        "output = model.generate(input_ids, attention_mask=attention_mask, max_length=100, num_return_sequences=1, no_repeat_ngram_size=2, top_k=50, top_p=0.95, temperature=0.7)\n",
        "\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VB4AbelO5Je",
        "outputId": "2b4b9f23-c2b0-4ec4-8ea1-cf633ad76235"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a distant future, humanity has discovered a way to make the world a better place.\n",
            "\n",
            "The world is a place of peace, harmony, and harmony. It is the place where the human race has been born. The world has become a world of love. And the love of the people is not only the greatest love, but the most important love in the universe. Love is love for the whole of humanity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4nQu2qdlO5Gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6D_L6p6PO5EG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}